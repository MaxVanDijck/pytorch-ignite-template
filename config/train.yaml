seed: 42 # rng seed for torch, random and numpy
checkpoint: False # Checkpoint to resume from, False otherwise

# Hardware specific parameters
compute:
  backend: # Can be either nccl, gloo, xla-tpu or left empty for None
  nproc_per_node: # Integer, left empty for None

# Commonly changed hyperparameters
params:
  batch_size: 128
  epochs: 20

# specify the default training parameters
defaults:
  - _self_
  - data: cifar10.yaml # dataset configuration
  - model: cifar10.yaml # architecture configuration
  - engine: cifar10.yaml # engine configuration

callbacks:
  add_lr_scheduler:
    _target_: src.callbacks.started.add_lr_scheduler

  print_learning_rate:
    _target_: src.callbacks.epoch_completed.print_learning_rate

  evaluate_model:
    _target_: src.callbacks.epoch_completed.evaluate_model
